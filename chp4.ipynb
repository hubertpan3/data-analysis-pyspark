{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Analyzing tabular data with pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/06/09 21:57:33 WARN Utils: Your hostname, LAPTOP-CDHH1LA0 resolves to a loopback address: 127.0.1.1; using 172.23.108.60 instead (on interface eth0)\n",
      "24/06/09 21:57:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/09 21:57:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: long (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate dataframe from list of lists\n",
    "my_grocery_list = [\n",
    "    [\"Bannana\", 2, 1.74],\n",
    "    [\"Apple\", 4, 2.04],\n",
    "    [\"Carrot\", 1, 1.09],\n",
    "    [\"Cake\", 1, 10.99]\n",
    "]\n",
    "\n",
    "df_grocery_list = spark.createDataFrame(my_grocery_list, [\"Item\", \"Quantity\", \"Price\"])\n",
    "\n",
    "df_grocery_list.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  litem|Price|\n",
      "+-------+-----+\n",
      "|bannana| 1.74|\n",
      "|  apple| 2.04|\n",
      "| carrot| 1.09|\n",
      "|   cake|10.99|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grocery_list.select(F.lower(F.col(\"Item\")).alias(\"litem\"), F.col(\"Price\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os \n",
    "DIRECTORY = \"./data/broadcast_logs\"\n",
    "logs = spark.read.csv(\n",
    "    os.path.join(DIRECTORY, \"BroadcastLogs_2018_Q3_M8_sample.CSV\"), # the path to the target file is the only mandatory param\n",
    "    sep=\"|\", # field delimiter \",\" by default but this can have issues if dealing with text that contains commas\n",
    "    header = True, # indicates if the file has a header row, can manually set column names with \"schema\" param\n",
    "    inferSchema=True, # tells python to guess at schema, can manually specify schema as well\n",
    "    timestampFormat = \"yyyy-MM-dd\", # tells python how to parse timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/09 21:57:42 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+----------+-------------------+----------------------+----------+---------------+-----------------+----------------+---------------+------------------+--------------+--------------------+------------+----------------+----------------+------------+------------+--------------------+----------------+--------+--------------------+------------------+----------------------+-------------+---------+---------+---------+---------+\n",
      "|BroadcastLogID|LogServiceID|   LogDate|SequenceNO|AudienceTargetAgeID|AudienceTargetEthnicID|CategoryID|ClosedCaptionID|CountryOfOriginID|DubDramaCreditID|EthnicProgramID|ProductionSourceID|ProgramClassID|FilmClassificationID|ExhibitionID|        Duration|         EndTime|LogEntryDate|ProductionNO|        ProgramTitle|       StartTime|Subtitle|NetworkAffiliationID|SpecialAttentionID|BroadcastOriginPointID|CompositionID|Producer1|Producer2|Language1|Language2|\n",
      "+--------------+------------+----------+----------+-------------------+----------------------+----------+---------------+-----------------+----------------+---------------+------------------+--------------+--------------------+------------+----------------+----------------+------------+------------+--------------------+----------------+--------+--------------------+------------------+----------------------+-------------+---------+---------+---------+---------+\n",
      "|    1196192316|        3157|2018-08-01|         1|                  4|                  NULL|        13|              3|                3|            NULL|           NULL|                10|            19|                NULL|           2|02:00:00.0000000|08:00:00.0000000|  2018-08-01|      A39082|   Newlywed and Dead|06:00:00.0000000|    NULL|                NULL|              NULL|                  NULL|         NULL|     NULL|     NULL|       94|     NULL|\n",
      "|    1196192317|        3157|2018-08-01|         2|               NULL|                  NULL|      NULL|              1|             NULL|            NULL|           NULL|              NULL|            20|                NULL|        NULL|00:00:30.0000000|06:13:45.0000000|  2018-08-01|        NULL|15-SPECIALTY CHAN...|06:13:15.0000000|    NULL|                NULL|              NULL|                  NULL|         NULL|     NULL|     NULL|     NULL|     NULL|\n",
      "|    1196192318|        3157|2018-08-01|         3|               NULL|                  NULL|      NULL|              1|             NULL|            NULL|           NULL|              NULL|             3|                NULL|        NULL|00:00:15.0000000|06:14:00.0000000|  2018-08-01|        NULL|3-PROCTER & GAMBL...|06:13:45.0000000|    NULL|                NULL|              NULL|                  NULL|         NULL|     NULL|     NULL|     NULL|     NULL|\n",
      "+--------------+------------+----------+----------+-------------------+----------------------+----------+---------------+-----------------+----------------+---------------+------------------+--------------+--------------------+------------+----------------+----------------+------------+------------+--------------------+----------------+--------+--------------------+------------------+----------------------+-------------+---------+---------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n",
      "+---------------+--------+-----+\n",
      "|           Item|Quantity|Price|\n",
      "+---------------+--------+-----+\n",
      "|Banana, organic|       1| 0.99|\n",
      "|           Pear|       7| 1.24|\n",
      "|Cake, chocolate|       1| 14.5|\n",
      "+---------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = spark.read.csv(os.path.join(\"data\", \"sample.csv\"), sep=\",\", header=True, quote=\"$\", inferSchema=True)\n",
    "sample.printSchema()\n",
    "sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BroadcastLogID', 'LogServiceID', 'LogDate', 'SequenceNO', 'AudienceTargetAgeID', 'AudienceTargetEthnicID', 'CategoryID', 'ClosedCaptionID', 'CountryOfOriginID', 'DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID', 'ProgramClassID', 'FilmClassificationID', 'ExhibitionID', 'Duration', 'EndTime', 'LogEntryDate', 'ProductionNO', 'ProgramTitle', 'StartTime', 'Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID', 'BroadcastOriginPointID', 'CompositionID', 'Producer1', 'Producer2', 'Language1', 'Language2']\n"
     ]
    }
   ],
   "source": [
    "print(logs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogId|LogServiceID|LogDate   |\n",
      "+--------------+------------+----------+\n",
      "|1196192316    |3157        |2018-08-01|\n",
      "|1196192317    |3157        |2018-08-01|\n",
      "|1196192318    |3157        |2018-08-01|\n",
      "|1196192319    |3157        |2018-08-01|\n",
      "|1196192320    |3157        |2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(\"BroadcastLogId\", \"LogServiceID\", \"LogDate\").show(5, False) # 5 for five rows, False to not truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogId|LogServiceID|   LogDate|\n",
      "+--------------+------------+----------+\n",
      "|    1196192316|        3157|2018-08-01|\n",
      "|    1196192317|        3157|2018-08-01|\n",
      "|    1196192318|        3157|2018-08-01|\n",
      "|    1196192319|        3157|2018-08-01|\n",
      "|    1196192320|        3157|2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can also use \"destructuring\" to expand a list structure into a list of inputs\n",
    "# (destructuring equivalent of the above)\n",
    "logs.select(*[\"BroadcastLogId\", \"LogServiceID\", \"LogDate\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['BroadcastLogID', 'LogServiceID', 'LogDate'], dtype='<U22'), array(['SequenceNO', 'AudienceTargetAgeID', 'AudienceTargetEthnicID'],\n",
      "      dtype='<U22'), array(['CategoryID', 'ClosedCaptionID', 'CountryOfOriginID'], dtype='<U22'), array(['DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID'],\n",
      "      dtype='<U22'), array(['ProgramClassID', 'FilmClassificationID', 'ExhibitionID'],\n",
      "      dtype='<U22'), array(['Duration', 'EndTime', 'LogEntryDate'], dtype='<U22'), array(['ProductionNO', 'ProgramTitle', 'StartTime'], dtype='<U22'), array(['Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID'],\n",
      "      dtype='<U22'), array(['BroadcastOriginPointID', 'CompositionID', 'Producer1'],\n",
      "      dtype='<U22'), array(['Producer2', 'Language1', 'Language2'], dtype='<U22')]\n"
     ]
    }
   ],
   "source": [
    "# columns of logs dataframe in groups of 3\n",
    "import numpy as np\n",
    "\n",
    "column_split = np.array_split( # split numpy array into n components\n",
    "    np.array(logs.columns), # the numpy array to split\n",
    "    len(logs.columns) // 3 # n (the number of subgroups) is determined via integer division by 3 (the target sublist size)\n",
    "    )\n",
    "print(column_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogID|LogServiceID|LogDate   |\n",
      "+--------------+------------+----------+\n",
      "|1196192316    |3157        |2018-08-01|\n",
      "|1196192317    |3157        |2018-08-01|\n",
      "|1196192318    |3157        |2018-08-01|\n",
      "|1196192319    |3157        |2018-08-01|\n",
      "|1196192320    |3157        |2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+-------------------+----------------------+\n",
      "|SequenceNO|AudienceTargetAgeID|AudienceTargetEthnicID|\n",
      "+----------+-------------------+----------------------+\n",
      "|1         |4                  |NULL                  |\n",
      "|2         |NULL               |NULL                  |\n",
      "|3         |NULL               |NULL                  |\n",
      "|4         |NULL               |NULL                  |\n",
      "|5         |NULL               |NULL                  |\n",
      "+----------+-------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------------+-----------------+\n",
      "|CategoryID|ClosedCaptionID|CountryOfOriginID|\n",
      "+----------+---------------+-----------------+\n",
      "|13        |3              |3                |\n",
      "|NULL      |1              |NULL             |\n",
      "|NULL      |1              |NULL             |\n",
      "|NULL      |1              |NULL             |\n",
      "|NULL      |1              |NULL             |\n",
      "+----------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+---------------+------------------+\n",
      "|DubDramaCreditID|EthnicProgramID|ProductionSourceID|\n",
      "+----------------+---------------+------------------+\n",
      "|NULL            |NULL           |10                |\n",
      "|NULL            |NULL           |NULL              |\n",
      "|NULL            |NULL           |NULL              |\n",
      "|NULL            |NULL           |NULL              |\n",
      "|NULL            |NULL           |NULL              |\n",
      "+----------------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+--------------------+------------+\n",
      "|ProgramClassID|FilmClassificationID|ExhibitionID|\n",
      "+--------------+--------------------+------------+\n",
      "|19            |NULL                |2           |\n",
      "|20            |NULL                |NULL        |\n",
      "|3             |NULL                |NULL        |\n",
      "|3             |NULL                |NULL        |\n",
      "|3             |NULL                |NULL        |\n",
      "+--------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+----------------+------------+\n",
      "|Duration        |EndTime         |LogEntryDate|\n",
      "+----------------+----------------+------------+\n",
      "|02:00:00.0000000|08:00:00.0000000|2018-08-01  |\n",
      "|00:00:30.0000000|06:13:45.0000000|2018-08-01  |\n",
      "|00:00:15.0000000|06:14:00.0000000|2018-08-01  |\n",
      "|00:00:15.0000000|06:14:15.0000000|2018-08-01  |\n",
      "|00:00:15.0000000|06:14:30.0000000|2018-08-01  |\n",
      "+----------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+-------------------------------------------+----------------+\n",
      "|ProductionNO|ProgramTitle                               |StartTime       |\n",
      "+------------+-------------------------------------------+----------------+\n",
      "|A39082      |Newlywed and Dead                          |06:00:00.0000000|\n",
      "|NULL        |15-SPECIALTY CHANNELS-Canadian Generic     |06:13:15.0000000|\n",
      "|NULL        |3-PROCTER & GAMBLE INC-Anti-Perspirant 3rd |06:13:45.0000000|\n",
      "|NULL        |12-CREDIT KARMA-Bank/Credit Union/Trust 3rd|06:14:00.0000000|\n",
      "|NULL        |3-L'OREAL CANADA-Hair Products 3rd         |06:14:15.0000000|\n",
      "+------------+-------------------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------------------+------------------+\n",
      "|Subtitle|NetworkAffiliationID|SpecialAttentionID|\n",
      "+--------+--------------------+------------------+\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "+--------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------+-------------+---------+\n",
      "|BroadcastOriginPointID|CompositionID|Producer1|\n",
      "+----------------------+-------------+---------+\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "+----------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+---------+\n",
      "|Producer2|Language1|Language2|\n",
      "+---------+---------+---------+\n",
      "|NULL     |94       |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in column_split:\n",
    "    logs.select(*x).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogServiceID', 'LogDate', 'AudienceTargetAgeID', 'AudienceTargetEthnicID', 'CategoryID', 'ClosedCaptionID', 'CountryOfOriginID', 'DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID', 'ProgramClassID', 'FilmClassificationID', 'ExhibitionID', 'Duration', 'EndTime', 'LogEntryDate', 'ProductionNO', 'ProgramTitle', 'StartTime', 'Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID', 'BroadcastOriginPointID', 'CompositionID', 'Producer1', 'Producer2', 'Language1', 'Language2']\n",
      "BroadcastLogID present prior to drop: False\n",
      "BroadcastLogID present post drop: False\n"
     ]
    }
   ],
   "source": [
    "# in addition to selecting only the columns that you want, you can also drop columns from an existing dataframe\n",
    "# this can be done with the \"drop\" method\n",
    "print(logs.columns)\n",
    "print(f\"BroadcastLogID present prior to drop: {'BroadcastLogID' in logs.columns}\")\n",
    "\n",
    "logs = logs.drop(\"BroadcastLogID\", \"SequenceNO\") # logs.drop returns a new dataframe, so we reassign it to logs to overwrite original\n",
    "\n",
    "print(f\"BroadcastLogID present post drop: {'BroadcastLogID' in logs.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to the drop command but with select\n",
    "logs = logs.select(*[x for x in logs.columns if x not in [\"BroadcastLogID\", \"SequenceNO\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.2\n",
    "\n",
    "What is the printed result of this code?\n",
    "\n",
    "sample_frame.columns # => ['item', 'price', 'quantity', 'UPC']\n",
    " \n",
    "print(sample_frame.drop('item', 'UPC', 'prices').columns)\n",
    "a) ['item' 'UPC']\n",
    "\n",
    "b) ['item', 'upc']\n",
    "\n",
    "c) ['price', 'quantity']\n",
    "\n",
    "d) ['price', 'quantity', 'UPC']\n",
    "\n",
    "e) Raises an error\n",
    "--------\n",
    "returns ['price', 'quantity'] which is c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add new columns with withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|        Duration|\n",
      "+----------------+\n",
      "|02:00:00.0000000|\n",
      "|00:00:30.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('Duration', 'string')]\n"
     ]
    }
   ],
   "source": [
    "#adding a new col with select (the long way vs withColumn)\n",
    "logs.select(F.col(\"Duration\")).show(5)\n",
    "\n",
    "# the dtypes attribute contains the column and its type wrapped in a tuple\n",
    "print(logs.select(F.col(\"Duration\")).dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogServiceID', 'int'),\n",
       " ('LogDate', 'date'),\n",
       " ('AudienceTargetAgeID', 'int'),\n",
       " ('AudienceTargetEthnicID', 'int'),\n",
       " ('CategoryID', 'int'),\n",
       " ('ClosedCaptionID', 'int'),\n",
       " ('CountryOfOriginID', 'int'),\n",
       " ('DubDramaCreditID', 'int'),\n",
       " ('EthnicProgramID', 'int'),\n",
       " ('ProductionSourceID', 'int'),\n",
       " ('ProgramClassID', 'int'),\n",
       " ('FilmClassificationID', 'int'),\n",
       " ('ExhibitionID', 'int'),\n",
       " ('Duration', 'string'),\n",
       " ('EndTime', 'string'),\n",
       " ('LogEntryDate', 'date'),\n",
       " ('ProductionNO', 'string'),\n",
       " ('ProgramTitle', 'string'),\n",
       " ('StartTime', 'string'),\n",
       " ('Subtitle', 'string'),\n",
       " ('NetworkAffiliationID', 'int'),\n",
       " ('SpecialAttentionID', 'int'),\n",
       " ('BroadcastOriginPointID', 'int'),\n",
       " ('CompositionID', 'int'),\n",
       " ('Producer1', 'string'),\n",
       " ('Producer2', 'string'),\n",
       " ('Language1', 'int'),\n",
       " ('Language2', 'int')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:======>                                                   (1 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-----------+-----------+\n",
      "|        Duration|dur_hours|dur_minutes|dur_seconds|\n",
      "+----------------+---------+-----------+-----------+\n",
      "|00:04:52.0000000|        0|          4|         52|\n",
      "|00:10:06.0000000|        0|         10|          6|\n",
      "|00:09:52.0000000|        0|          9|         52|\n",
      "|00:04:26.0000000|        0|          4|         26|\n",
      "|00:14:59.0000000|        0|         14|         59|\n",
      "+----------------+---------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "logs.select(\n",
    "    F.col(\"Duration\"), # original column\n",
    "    F.col(\"Duration\").substr(1,2).cast(\"int\").alias(\"dur_hours\"), # hours # python is 1 indexed, substr takes start, length, cast to int, and alias for readability\n",
    "    F.col(\"Duration\").substr(4,2).cast(\"int\").alias(\"dur_minutes\"), # minutes\n",
    "    F.col(\"Duration\").substr(7,2).cast(\"int\").alias(\"dur_seconds\") # seconds\n",
    ").distinct().show(5) # distinct used to remove duplicates to reduce clutter during display\n",
    "\n",
    "# alternatively we could use the datetime and timedelta python constructs through udfs, but they can be slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|        Duration|Duration_seconds|\n",
      "+----------------+----------------+\n",
      "|01:59:30.0000000|            7170|\n",
      "|00:31:00.0000000|            1860|\n",
      "|00:28:08.0000000|            1688|\n",
      "|00:32:00.0000000|            1920|\n",
      "|00:30:00.0000000|            1800|\n",
      "+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine columns into a single duration (seconds)\n",
    "logs.select(\n",
    "    F.col(\"Duration\"),\n",
    "    (\n",
    "        F.col(\"Duration\").substr(1,2).cast(\"int\") * 60 * 60\n",
    "        + F.col(\"Duration\").substr(4,2).cast(\"int\") * 60\n",
    "        + F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "    ).alias(\"Duration_seconds\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper method to generate Duration_seconds col\n",
    "\n",
    "def generate_Duration_seconds(raw_duration):\n",
    "    return (\n",
    "        F.col(\"Duration\").substr(1,2).cast(\"int\") * 60 * 60\n",
    "        + F.col(\"Duration\").substr(4,2).cast(\"int\") * 60\n",
    "        + F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- Duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumn allows you to easily add a column to a duplicate of a dataframe based off of a combination of other columns\n",
    "logs = logs.withColumn(\"Duration_seconds\", generate_Duration_seconds(F.col(\"Duration\")))\n",
    "logs.printSchema()\n",
    "\n",
    "# performance note, if you are making 100+ new columns, \"select\" will be faster than \"withColumn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bookmark 4.4.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
