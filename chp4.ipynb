{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Analyzing tabular data with pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/06/15 18:28:09 WARN Utils: Your hostname, LAPTOP-CDHH1LA0 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/06/15 18:28:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/15 18:28:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 35648)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/hubert/data-analysis-pyspark/.venv/lib/python3.11/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/hubert/data-analysis-pyspark/.venv/lib/python3.11/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/home/hubert/data-analysis-pyspark/.venv/lib/python3.11/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hubert/data-analysis-pyspark/.venv/lib/python3.11/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: long (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate dataframe from list of lists\n",
    "my_grocery_list = [\n",
    "    [\"Bannana\", 2, 1.74],\n",
    "    [\"Apple\", 4, 2.04],\n",
    "    [\"Carrot\", 1, 1.09],\n",
    "    [\"Cake\", 1, 10.99]\n",
    "]\n",
    "\n",
    "df_grocery_list = spark.createDataFrame(my_grocery_list, [\"Item\", \"Quantity\", \"Price\"])\n",
    "\n",
    "df_grocery_list.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|  litem|Price|\n",
      "+-------+-----+\n",
      "|bannana| 1.74|\n",
      "|  apple| 2.04|\n",
      "| carrot| 1.09|\n",
      "|   cake|10.99|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grocery_list.select(F.lower(F.col(\"Item\")).alias(\"litem\"), F.col(\"Price\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os \n",
    "DIRECTORY = \"./data/broadcast_logs\"\n",
    "logs = spark.read.csv(\n",
    "    os.path.join(DIRECTORY, \"BroadcastLogs_2018_Q3_M8_sample.CSV\"), # the path to the target file is the only mandatory param\n",
    "    sep=\"|\", # field delimiter \",\" by default but this can have issues if dealing with text that contains commas\n",
    "    header = True, # indicates if the file has a header row, can manually set column names with \"schema\" param\n",
    "    inferSchema=True, # tells python to guess at schema, can manually specify schema as well\n",
    "    timestampFormat = \"yyyy-MM-dd\", # tells python how to parse timestamps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- BroadcastLogID: integer (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- SequenceNO: integer (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/15 18:28:18 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+----------+-------------------+----------------------+----------+---------------+-----------------+----------------+---------------+------------------+--------------+--------------------+------------+----------------+----------------+------------+------------+--------------------+----------------+--------+--------------------+------------------+----------------------+-------------+---------+---------+---------+---------+\n",
      "|BroadcastLogID|LogServiceID|   LogDate|SequenceNO|AudienceTargetAgeID|AudienceTargetEthnicID|CategoryID|ClosedCaptionID|CountryOfOriginID|DubDramaCreditID|EthnicProgramID|ProductionSourceID|ProgramClassID|FilmClassificationID|ExhibitionID|        Duration|         EndTime|LogEntryDate|ProductionNO|        ProgramTitle|       StartTime|Subtitle|NetworkAffiliationID|SpecialAttentionID|BroadcastOriginPointID|CompositionID|Producer1|Producer2|Language1|Language2|\n",
      "+--------------+------------+----------+----------+-------------------+----------------------+----------+---------------+-----------------+----------------+---------------+------------------+--------------+--------------------+------------+----------------+----------------+------------+------------+--------------------+----------------+--------+--------------------+------------------+----------------------+-------------+---------+---------+---------+---------+\n",
      "|    1196192316|        3157|2018-08-01|         1|                  4|                  NULL|        13|              3|                3|            NULL|           NULL|                10|            19|                NULL|           2|02:00:00.0000000|08:00:00.0000000|  2018-08-01|      A39082|   Newlywed and Dead|06:00:00.0000000|    NULL|                NULL|              NULL|                  NULL|         NULL|     NULL|     NULL|       94|     NULL|\n",
      "|    1196192317|        3157|2018-08-01|         2|               NULL|                  NULL|      NULL|              1|             NULL|            NULL|           NULL|              NULL|            20|                NULL|        NULL|00:00:30.0000000|06:13:45.0000000|  2018-08-01|        NULL|15-SPECIALTY CHAN...|06:13:15.0000000|    NULL|                NULL|              NULL|                  NULL|         NULL|     NULL|     NULL|     NULL|     NULL|\n",
      "|    1196192318|        3157|2018-08-01|         3|               NULL|                  NULL|      NULL|              1|             NULL|            NULL|           NULL|              NULL|             3|                NULL|        NULL|00:00:15.0000000|06:14:00.0000000|  2018-08-01|        NULL|3-PROCTER & GAMBL...|06:13:45.0000000|    NULL|                NULL|              NULL|                  NULL|         NULL|     NULL|     NULL|     NULL|     NULL|\n",
      "+--------------+------------+----------+----------+-------------------+----------------------+----------+---------------+-----------------+----------------+---------------+------------------+--------------+--------------------+------------+----------------+----------------+------------+------------+--------------------+----------------+--------+--------------------+------------------+----------------------+-------------+---------+---------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      "\n",
      "+---------------+--------+-----+\n",
      "|           Item|Quantity|Price|\n",
      "+---------------+--------+-----+\n",
      "|Banana, organic|       1| 0.99|\n",
      "|           Pear|       7| 1.24|\n",
      "|Cake, chocolate|       1| 14.5|\n",
      "+---------------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = spark.read.csv(os.path.join(\"data\", \"sample.csv\"), sep=\",\", header=True, quote=\"$\", inferSchema=True)\n",
    "sample.printSchema()\n",
    "sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BroadcastLogID', 'LogServiceID', 'LogDate', 'SequenceNO', 'AudienceTargetAgeID', 'AudienceTargetEthnicID', 'CategoryID', 'ClosedCaptionID', 'CountryOfOriginID', 'DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID', 'ProgramClassID', 'FilmClassificationID', 'ExhibitionID', 'Duration', 'EndTime', 'LogEntryDate', 'ProductionNO', 'ProgramTitle', 'StartTime', 'Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID', 'BroadcastOriginPointID', 'CompositionID', 'Producer1', 'Producer2', 'Language1', 'Language2']\n"
     ]
    }
   ],
   "source": [
    "print(logs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogId|LogServiceID|LogDate   |\n",
      "+--------------+------------+----------+\n",
      "|1196192316    |3157        |2018-08-01|\n",
      "|1196192317    |3157        |2018-08-01|\n",
      "|1196192318    |3157        |2018-08-01|\n",
      "|1196192319    |3157        |2018-08-01|\n",
      "|1196192320    |3157        |2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(\"BroadcastLogId\", \"LogServiceID\", \"LogDate\").show(5, False) # 5 for five rows, False to not truncate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogId|LogServiceID|   LogDate|\n",
      "+--------------+------------+----------+\n",
      "|    1196192316|        3157|2018-08-01|\n",
      "|    1196192317|        3157|2018-08-01|\n",
      "|    1196192318|        3157|2018-08-01|\n",
      "|    1196192319|        3157|2018-08-01|\n",
      "|    1196192320|        3157|2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can also use \"destructuring\" to expand a list structure into a list of inputs\n",
    "# (destructuring equivalent of the above)\n",
    "logs.select(*[\"BroadcastLogId\", \"LogServiceID\", \"LogDate\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['BroadcastLogID', 'LogServiceID', 'LogDate'], dtype='<U22'), array(['SequenceNO', 'AudienceTargetAgeID', 'AudienceTargetEthnicID'],\n",
      "      dtype='<U22'), array(['CategoryID', 'ClosedCaptionID', 'CountryOfOriginID'], dtype='<U22'), array(['DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID'],\n",
      "      dtype='<U22'), array(['ProgramClassID', 'FilmClassificationID', 'ExhibitionID'],\n",
      "      dtype='<U22'), array(['Duration', 'EndTime', 'LogEntryDate'], dtype='<U22'), array(['ProductionNO', 'ProgramTitle', 'StartTime'], dtype='<U22'), array(['Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID'],\n",
      "      dtype='<U22'), array(['BroadcastOriginPointID', 'CompositionID', 'Producer1'],\n",
      "      dtype='<U22'), array(['Producer2', 'Language1', 'Language2'], dtype='<U22')]\n"
     ]
    }
   ],
   "source": [
    "# columns of logs dataframe in groups of 3\n",
    "import numpy as np\n",
    "\n",
    "column_split = np.array_split( # split numpy array into n components\n",
    "    np.array(logs.columns), # the numpy array to split\n",
    "    len(logs.columns) // 3 # n (the number of subgroups) is determined via integer division by 3 (the target sublist size)\n",
    "    )\n",
    "print(column_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+----------+\n",
      "|BroadcastLogID|LogServiceID|LogDate   |\n",
      "+--------------+------------+----------+\n",
      "|1196192316    |3157        |2018-08-01|\n",
      "|1196192317    |3157        |2018-08-01|\n",
      "|1196192318    |3157        |2018-08-01|\n",
      "|1196192319    |3157        |2018-08-01|\n",
      "|1196192320    |3157        |2018-08-01|\n",
      "+--------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+-------------------+----------------------+\n",
      "|SequenceNO|AudienceTargetAgeID|AudienceTargetEthnicID|\n",
      "+----------+-------------------+----------------------+\n",
      "|1         |4                  |NULL                  |\n",
      "|2         |NULL               |NULL                  |\n",
      "|3         |NULL               |NULL                  |\n",
      "|4         |NULL               |NULL                  |\n",
      "|5         |NULL               |NULL                  |\n",
      "+----------+-------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+---------------+-----------------+\n",
      "|CategoryID|ClosedCaptionID|CountryOfOriginID|\n",
      "+----------+---------------+-----------------+\n",
      "|13        |3              |3                |\n",
      "|NULL      |1              |NULL             |\n",
      "|NULL      |1              |NULL             |\n",
      "|NULL      |1              |NULL             |\n",
      "|NULL      |1              |NULL             |\n",
      "+----------+---------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+---------------+------------------+\n",
      "|DubDramaCreditID|EthnicProgramID|ProductionSourceID|\n",
      "+----------------+---------------+------------------+\n",
      "|NULL            |NULL           |10                |\n",
      "|NULL            |NULL           |NULL              |\n",
      "|NULL            |NULL           |NULL              |\n",
      "|NULL            |NULL           |NULL              |\n",
      "|NULL            |NULL           |NULL              |\n",
      "+----------------+---------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+--------------------+------------+\n",
      "|ProgramClassID|FilmClassificationID|ExhibitionID|\n",
      "+--------------+--------------------+------------+\n",
      "|19            |NULL                |2           |\n",
      "|20            |NULL                |NULL        |\n",
      "|3             |NULL                |NULL        |\n",
      "|3             |NULL                |NULL        |\n",
      "|3             |NULL                |NULL        |\n",
      "+--------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+----------------+------------+\n",
      "|Duration        |EndTime         |LogEntryDate|\n",
      "+----------------+----------------+------------+\n",
      "|02:00:00.0000000|08:00:00.0000000|2018-08-01  |\n",
      "|00:00:30.0000000|06:13:45.0000000|2018-08-01  |\n",
      "|00:00:15.0000000|06:14:00.0000000|2018-08-01  |\n",
      "|00:00:15.0000000|06:14:15.0000000|2018-08-01  |\n",
      "|00:00:15.0000000|06:14:30.0000000|2018-08-01  |\n",
      "+----------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+-------------------------------------------+----------------+\n",
      "|ProductionNO|ProgramTitle                               |StartTime       |\n",
      "+------------+-------------------------------------------+----------------+\n",
      "|A39082      |Newlywed and Dead                          |06:00:00.0000000|\n",
      "|NULL        |15-SPECIALTY CHANNELS-Canadian Generic     |06:13:15.0000000|\n",
      "|NULL        |3-PROCTER & GAMBLE INC-Anti-Perspirant 3rd |06:13:45.0000000|\n",
      "|NULL        |12-CREDIT KARMA-Bank/Credit Union/Trust 3rd|06:14:00.0000000|\n",
      "|NULL        |3-L'OREAL CANADA-Hair Products 3rd         |06:14:15.0000000|\n",
      "+------------+-------------------------------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+--------------------+------------------+\n",
      "|Subtitle|NetworkAffiliationID|SpecialAttentionID|\n",
      "+--------+--------------------+------------------+\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "|NULL    |NULL                |NULL              |\n",
      "+--------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------------+-------------+---------+\n",
      "|BroadcastOriginPointID|CompositionID|Producer1|\n",
      "+----------------------+-------------+---------+\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "|NULL                  |NULL         |NULL     |\n",
      "+----------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+---------+\n",
      "|Producer2|Language1|Language2|\n",
      "+---------+---------+---------+\n",
      "|NULL     |94       |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "|NULL     |NULL     |NULL     |\n",
      "+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in column_split:\n",
    "    logs.select(*x).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BroadcastLogID', 'LogServiceID', 'LogDate', 'SequenceNO', 'AudienceTargetAgeID', 'AudienceTargetEthnicID', 'CategoryID', 'ClosedCaptionID', 'CountryOfOriginID', 'DubDramaCreditID', 'EthnicProgramID', 'ProductionSourceID', 'ProgramClassID', 'FilmClassificationID', 'ExhibitionID', 'Duration', 'EndTime', 'LogEntryDate', 'ProductionNO', 'ProgramTitle', 'StartTime', 'Subtitle', 'NetworkAffiliationID', 'SpecialAttentionID', 'BroadcastOriginPointID', 'CompositionID', 'Producer1', 'Producer2', 'Language1', 'Language2']\n",
      "BroadcastLogID present prior to drop: True\n",
      "BroadcastLogID present post drop: False\n"
     ]
    }
   ],
   "source": [
    "# in addition to selecting only the columns that you want, you can also drop columns from an existing dataframe\n",
    "# this can be done with the \"drop\" method\n",
    "print(logs.columns)\n",
    "print(f\"BroadcastLogID present prior to drop: {'BroadcastLogID' in logs.columns}\")\n",
    "\n",
    "logs = logs.drop(\"BroadcastLogID\", \"SequenceNO\") # logs.drop returns a new dataframe, so we reassign it to logs to overwrite original\n",
    "\n",
    "print(f\"BroadcastLogID present post drop: {'BroadcastLogID' in logs.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent to the drop command but with select\n",
    "logs = logs.select(*[x for x in logs.columns if x not in [\"BroadcastLogID\", \"SequenceNO\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4.2\n",
    "\n",
    "What is the printed result of this code?\n",
    "\n",
    "sample_frame.columns # => ['item', 'price', 'quantity', 'UPC']\n",
    " \n",
    "print(sample_frame.drop('item', 'UPC', 'prices').columns)\n",
    "a) ['item' 'UPC']\n",
    "\n",
    "b) ['item', 'upc']\n",
    "\n",
    "c) ['price', 'quantity']\n",
    "\n",
    "d) ['price', 'quantity', 'UPC']\n",
    "\n",
    "e) Raises an error\n",
    "--------\n",
    "returns ['price', 'quantity'] which is c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add new columns with withColumn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|        Duration|\n",
      "+----------------+\n",
      "|02:00:00.0000000|\n",
      "|00:00:30.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "|00:00:15.0000000|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "[('Duration', 'string')]\n"
     ]
    }
   ],
   "source": [
    "#adding a new col with select (the long way vs withColumn)\n",
    "logs.select(F.col(\"Duration\")).show(5)\n",
    "\n",
    "# the dtypes attribute contains the column and its type wrapped in a tuple\n",
    "print(logs.select(F.col(\"Duration\")).dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogServiceID', 'int'),\n",
       " ('LogDate', 'date'),\n",
       " ('AudienceTargetAgeID', 'int'),\n",
       " ('AudienceTargetEthnicID', 'int'),\n",
       " ('CategoryID', 'int'),\n",
       " ('ClosedCaptionID', 'int'),\n",
       " ('CountryOfOriginID', 'int'),\n",
       " ('DubDramaCreditID', 'int'),\n",
       " ('EthnicProgramID', 'int'),\n",
       " ('ProductionSourceID', 'int'),\n",
       " ('ProgramClassID', 'int'),\n",
       " ('FilmClassificationID', 'int'),\n",
       " ('ExhibitionID', 'int'),\n",
       " ('Duration', 'string'),\n",
       " ('EndTime', 'string'),\n",
       " ('LogEntryDate', 'date'),\n",
       " ('ProductionNO', 'string'),\n",
       " ('ProgramTitle', 'string'),\n",
       " ('StartTime', 'string'),\n",
       " ('Subtitle', 'string'),\n",
       " ('NetworkAffiliationID', 'int'),\n",
       " ('SpecialAttentionID', 'int'),\n",
       " ('BroadcastOriginPointID', 'int'),\n",
       " ('CompositionID', 'int'),\n",
       " ('Producer1', 'string'),\n",
       " ('Producer2', 'string'),\n",
       " ('Language1', 'int'),\n",
       " ('Language2', 'int')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+-----------+-----------+\n",
      "|        Duration|dur_hours|dur_minutes|dur_seconds|\n",
      "+----------------+---------+-----------+-----------+\n",
      "|00:04:52.0000000|        0|          4|         52|\n",
      "|00:10:06.0000000|        0|         10|          6|\n",
      "|00:09:52.0000000|        0|          9|         52|\n",
      "|00:04:26.0000000|        0|          4|         26|\n",
      "|00:14:59.0000000|        0|         14|         59|\n",
      "+----------------+---------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs.select(\n",
    "    F.col(\"Duration\"), # original column\n",
    "    F.col(\"Duration\").substr(1,2).cast(\"int\").alias(\"dur_hours\"), # hours # python is 1 indexed, substr takes start, length, cast to int, and alias for readability\n",
    "    F.col(\"Duration\").substr(4,2).cast(\"int\").alias(\"dur_minutes\"), # minutes\n",
    "    F.col(\"Duration\").substr(7,2).cast(\"int\").alias(\"dur_seconds\") # seconds\n",
    ").distinct().show(5) # distinct used to remove duplicates to reduce clutter during display\n",
    "\n",
    "# alternatively we could use the datetime and timedelta python constructs through udfs, but they can be slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|        Duration|Duration_seconds|\n",
      "+----------------+----------------+\n",
      "|01:59:30.0000000|            7170|\n",
      "|00:31:00.0000000|            1860|\n",
      "|00:28:08.0000000|            1688|\n",
      "|00:32:00.0000000|            1920|\n",
      "|00:30:00.0000000|            1800|\n",
      "+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine columns into a single duration (seconds)\n",
    "logs.select(\n",
    "    F.col(\"Duration\"),\n",
    "    (\n",
    "        F.col(\"Duration\").substr(1,2).cast(\"int\") * 60 * 60\n",
    "        + F.col(\"Duration\").substr(4,2).cast(\"int\") * 60\n",
    "        + F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "    ).alias(\"Duration_seconds\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper method to generate Duration_seconds col\n",
    "\n",
    "def generate_Duration_seconds(raw_duration):\n",
    "    return (\n",
    "        F.col(\"Duration\").substr(1,2).cast(\"int\") * 60 * 60\n",
    "        + F.col(\"Duration\").substr(4,2).cast(\"int\") * 60\n",
    "        + F.col(\"Duration\").substr(7,2).cast(\"int\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- Duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumn allows you to easily add a column to a duplicate of a dataframe based off of a combination of other columns\n",
    "logs = logs.withColumn(\"Duration_seconds\", generate_Duration_seconds(F.col(\"Duration\")))\n",
    "logs.printSchema()\n",
    "\n",
    "# performance note, if you are making 100+ new columns, \"select\" will be faster than \"withColumn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# columns in a dataframe can be renamed with \"withColumnRenamed\"\n",
    "\n",
    "logs = logs.withColumnRenamed(\"Duration_seconds\", \"duration_seconds\")\n",
    "logs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- logserviceid: integer (nullable = true)\n",
      " |-- logdate: date (nullable = true)\n",
      " |-- audiencetargetageid: integer (nullable = true)\n",
      " |-- audiencetargetethnicid: integer (nullable = true)\n",
      " |-- categoryid: integer (nullable = true)\n",
      " |-- closedcaptionid: integer (nullable = true)\n",
      " |-- countryoforiginid: integer (nullable = true)\n",
      " |-- dubdramacreditid: integer (nullable = true)\n",
      " |-- ethnicprogramid: integer (nullable = true)\n",
      " |-- productionsourceid: integer (nullable = true)\n",
      " |-- programclassid: integer (nullable = true)\n",
      " |-- filmclassificationid: integer (nullable = true)\n",
      " |-- exhibitionid: integer (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- endtime: string (nullable = true)\n",
      " |-- logentrydate: date (nullable = true)\n",
      " |-- productionno: string (nullable = true)\n",
      " |-- programtitle: string (nullable = true)\n",
      " |-- starttime: string (nullable = true)\n",
      " |-- subtitle: string (nullable = true)\n",
      " |-- networkaffiliationid: integer (nullable = true)\n",
      " |-- specialattentionid: integer (nullable = true)\n",
      " |-- broadcastoriginpointid: integer (nullable = true)\n",
      " |-- compositionid: integer (nullable = true)\n",
      " |-- producer1: string (nullable = true)\n",
      " |-- producer2: string (nullable = true)\n",
      " |-- language1: integer (nullable = true)\n",
      " |-- language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can lowercase or otherwise apply the same modification to the all of the columns in the dataframe via\n",
    "\n",
    "logs.toDF(*[x.lower() for x in logs.columns]).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- AudienceTargetAgeID: integer (nullable = true)\n",
      " |-- AudienceTargetEthnicID: integer (nullable = true)\n",
      " |-- BroadcastOriginPointID: integer (nullable = true)\n",
      " |-- CategoryID: integer (nullable = true)\n",
      " |-- ClosedCaptionID: integer (nullable = true)\n",
      " |-- CompositionID: integer (nullable = true)\n",
      " |-- CountryOfOriginID: integer (nullable = true)\n",
      " |-- DubDramaCreditID: integer (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- EthnicProgramID: integer (nullable = true)\n",
      " |-- ExhibitionID: integer (nullable = true)\n",
      " |-- FilmClassificationID: integer (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- LogServiceID: integer (nullable = true)\n",
      " |-- NetworkAffiliationID: integer (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProductionSourceID: integer (nullable = true)\n",
      " |-- ProgramClassID: integer (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- SpecialAttentionID: integer (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can use select to reorder the columns\n",
    "\n",
    "logs.select(sorted(logs.columns)).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show df:\n",
      "+-------+---------+------+-----+\n",
      "|   Item|QuantityN|PriceN|total|\n",
      "+-------+---------+------+-----+\n",
      "|Bannana|        2|  1.74| 3.48|\n",
      "|  Apple|        4|  2.04| 8.16|\n",
      "| Carrot|        1|  1.09| 1.09|\n",
      "|   Cake|        1| 10.99|10.99|\n",
      "+-------+---------+------+-----+\n",
      "\n",
      "describe:\n",
      "+-------+------+------------------+-----------------+-----------------+\n",
      "|summary|  Item|         QuantityN|           PriceN|            total|\n",
      "+-------+------+------------------+-----------------+-----------------+\n",
      "|  count|     4|                 4|                4|                4|\n",
      "|   mean|  NULL|               2.0|3.964999943971634| 5.92999991774559|\n",
      "| stddev|  NULL|1.4142135623730951| 4.70008853451048|4.472307256387503|\n",
      "|    min| Apple|                 1|             1.09|             1.09|\n",
      "|    max|Carrot|                 4|            10.99|            10.99|\n",
      "+-------+------+------------------+-----------------+-----------------+\n",
      "\n",
      "summary:\n",
      "+-------+------+------------------+-----------------+-----------------+\n",
      "|summary|  Item|         QuantityN|           PriceN|            total|\n",
      "+-------+------+------------------+-----------------+-----------------+\n",
      "|  count|     4|                 4|                4|                4|\n",
      "|   mean|  NULL|               2.0|3.964999943971634| 5.92999991774559|\n",
      "| stddev|  NULL|1.4142135623730951| 4.70008853451048|4.472307256387503|\n",
      "|    min| Apple|                 1|             1.09|             1.09|\n",
      "|    25%|  NULL|                 1|             1.09|             1.09|\n",
      "|    50%|  NULL|                 1|             1.74|             3.48|\n",
      "|    75%|  NULL|                 2|             2.04|             8.16|\n",
      "|    max|Carrot|                 4|            10.99|            10.99|\n",
      "+-------+------+------------------+-----------------+-----------------+\n",
      "\n",
      "single column describe ('QuantityN'):\n",
      "+-------+------------------+\n",
      "|summary|         QuantityN|\n",
      "+-------+------------------+\n",
      "|  count|                 4|\n",
      "|   mean|               2.0|\n",
      "| stddev|1.4142135623730951|\n",
      "|    min|                 1|\n",
      "|    max|                 4|\n",
      "+-------+------------------+\n",
      "\n",
      "single column summary with custom stats\n",
      "+-------+---------+\n",
      "|summary|QuantityN|\n",
      "+-------+---------+\n",
      "|    10%|        1|\n",
      "|    20%|        1|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#summarizing data with describe and summary \n",
    "df_grocery_list_typed = df_grocery_list.select(\n",
    "    F.column(\"Item\"), \n",
    "    F.to_number(F.column(\"Quantity\"), F.lit(\"999\")).alias(\"QuantityN\").cast('int'), #F.lit allows us to generate a column where every cell is the same value\n",
    "    F.try_to_number(F.column(\"Price\"), F.lit(\"99.99\")).alias(\"PriceN\").cast('float'),\n",
    "    F.try_multiply(\"QuantityN\", \"PriceN\").alias(\"total\").cast('float')\n",
    "    )\n",
    "print(f\"show df:\")\n",
    "df_grocery_list_typed.show()\n",
    "print(\"describe:\")\n",
    "df_grocery_list_typed.describe().show()\n",
    "print(\"summary:\")\n",
    "#summary is describe plus quartile info\n",
    "df_grocery_list_typed.summary().show(10)\n",
    "\n",
    "# describing a single column\n",
    "print(\"single column describe ('QuantityN'):\")\n",
    "df_grocery_list_typed.describe(['QuantityN']).show()\n",
    "\n",
    "# summary can also take in a custom list of statistics\n",
    "print(\"single column summary with custom stats:\")\n",
    "df_grocery_list_typed.select('QuantityN').summary('10%', '20%').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('Item', StringType(), True), StructField('QuantityN', IntegerType(), True), StructField('PriceN', FloatType(), True), StructField('total', FloatType(), True)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grocery_list_typed.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('Item', StringType(), True), StructField('Quantity', LongType(), True), StructField('Price', DoubleType(), True)])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grocery_list.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Item: string, Quantity: string, Price: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('LogServiceID', IntegerType(), True), StructField('LogDate', DateType(), True), StructField('AudienceTargetAgeID', IntegerType(), True), StructField('AudienceTargetEthnicID', IntegerType(), True), StructField('CategoryID', IntegerType(), True), StructField('ClosedCaptionID', IntegerType(), True), StructField('CountryOfOriginID', IntegerType(), True), StructField('DubDramaCreditID', IntegerType(), True), StructField('EthnicProgramID', IntegerType(), True), StructField('ProductionSourceID', IntegerType(), True), StructField('ProgramClassID', IntegerType(), True), StructField('FilmClassificationID', IntegerType(), True), StructField('ExhibitionID', IntegerType(), True), StructField('Duration', StringType(), True), StructField('EndTime', StringType(), True), StructField('LogEntryDate', DateType(), True), StructField('ProductionNO', StringType(), True), StructField('ProgramTitle', StringType(), True), StructField('StartTime', StringType(), True), StructField('Subtitle', StringType(), True), StructField('NetworkAffiliationID', IntegerType(), True), StructField('SpecialAttentionID', IntegerType(), True), StructField('BroadcastOriginPointID', IntegerType(), True), StructField('CompositionID', IntegerType(), True), StructField('Producer1', StringType(), True), StructField('Producer2', StringType(), True), StructField('Language1', IntegerType(), True), StructField('Language2', IntegerType(), True), StructField('duration_seconds', IntegerType(), True)])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3\n",
    "As shown below, reading in the logs csv without the optional parameters generates a dataframe with a single column \"_c0\" with a data type of \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|BroadcastLogID|Lo...|\n",
      "|1196192316|3157|2...|\n",
      "|1196192317|3157|2...|\n",
      "|1196192318|3157|2...|\n",
      "|1196192319|3157|2...|\n",
      "|1196192320|3157|2...|\n",
      "|1196192321|3157|2...|\n",
      "|1196192322|3157|2...|\n",
      "|1196192323|3157|2...|\n",
      "|1196192324|3157|2...|\n",
      "|1196192325|3157|2...|\n",
      "|1196192326|3157|2...|\n",
      "|1196192327|3157|2...|\n",
      "|1196192328|3157|2...|\n",
      "|1196192329|3157|2...|\n",
      "|1196192330|3157|2...|\n",
      "|1196192331|3157|2...|\n",
      "|1196192332|3157|2...|\n",
      "|1196192333|3157|2...|\n",
      "|1196192334|3157|2...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_raw = spark.read.csv(\n",
    "    os.path.join(DIRECTORY, \"BroadcastLogs_2018_Q3_M8_sample.CSV\") # the path to the target file is the only mandatory param\n",
    ")\n",
    "logs_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('_c0', StringType(), True)])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs_raw.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4\n",
    "Create a new dataframe from logs that only contains the columns with names that don't end with \"ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LogDate: date (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- EndTime: string (nullable = true)\n",
      " |-- LogEntryDate: date (nullable = true)\n",
      " |-- ProductionNO: string (nullable = true)\n",
      " |-- ProgramTitle: string (nullable = true)\n",
      " |-- StartTime: string (nullable = true)\n",
      " |-- Subtitle: string (nullable = true)\n",
      " |-- Producer1: string (nullable = true)\n",
      " |-- Producer2: string (nullable = true)\n",
      " |-- Language1: integer (nullable = true)\n",
      " |-- Language2: integer (nullable = true)\n",
      " |-- duration_seconds: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_clean = logs.select(*[x for x in logs.columns if x[-2:] != \"ID\"])\n",
    "logs_clean.schema\n",
    "logs_clean.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
